{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Inception_regression.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ad4adcab6f56456c913e9a744c4d22cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_18bd5cd59b4640bb8000358765aaa96c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f7fe7633f5174686b00d66b1f4ad16b7","IPY_MODEL_81cb44a81a4d463a8d6fc0608b088192"]}},"18bd5cd59b4640bb8000358765aaa96c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f7fe7633f5174686b00d66b1f4ad16b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_708f0de04cb54d9080d4f3898fcfe7d7","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":108857766,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":108857766,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_54c63c8d99964463990f3f7add5fe9aa"}},"81cb44a81a4d463a8d6fc0608b088192":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_970c2f54ad03494b9b572fe52f92954c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 104M/104M [01:07&lt;00:00, 1.61MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_90ad6fbbfcba4f7999ff0abd41cc7629"}},"708f0de04cb54d9080d4f3898fcfe7d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"54c63c8d99964463990f3f7add5fe9aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"970c2f54ad03494b9b572fe52f92954c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"90ad6fbbfcba4f7999ff0abd41cc7629":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"K9K1taBKQHAV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609494123010,"user_tz":-330,"elapsed":23982,"user":{"displayName":"Reshma Rameshbabu","photoUrl":"","userId":"00800467791840406492"}},"outputId":"64553d95-231f-448f-daa8-69926ef5abf0"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iy8RSatXO7G5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605414556627,"user_tz":-330,"elapsed":1732,"user":{"displayName":"Reshma Rameshbabu","photoUrl":"","userId":"00800467791840406492"}},"outputId":"f92a8d56-ea2a-4800-94e5-e944663a5da9"},"source":["!pwd\n","%cd \"/content/\"\n","!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","/content\n","/content\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_yTF4pyYb5bX"},"source":["Data Loader"]},{"cell_type":"code","metadata":{"id":"WdT2h-kYVebG"},"source":["import torch.utils.data as data\n","\n","from PIL import Image\n","import os\n","import os.path\n","import sys\n","import numpy as np\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.utils.data import TensorDataset, DataLoader, Dataset\n","import cv2\n","from sklearn import preprocessing\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GrAVmgE2j231","colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"status":"ok","timestamp":1608902334271,"user_tz":-330,"elapsed":28631,"user":{"displayName":"Reshma Rameshbabu","photoUrl":"","userId":"00800467791840406492"}},"outputId":"6f0cdd3d-d187-4832-f59e-b2fb8f9877f4"},"source":["image_ids = []\n","xs = []\n","ys = []\n","zs = []\n","c = 0\n","for dir, sub_dir, f in os.walk(\"/content/drive/My Drive/FYP/Dataset/entire/openEDS2020-GazePrediction/train/sequences\"):\n","  if len(f) > 0:\n","    c += 1\n","    f = sorted(f)\n","    seq_id = dir.split(\"/\")[-1]\n","    temp_images_ids = [seq_id+'_'+x for x in f]\n","    image_ids.extend(temp_images_ids)\n","    with open(\"/content/drive/My Drive/FYP/Dataset/entire/openEDS2020-GazePrediction/train/labels/\"+seq_id+\".txt\", mode = \"r\") as file:\n","      labels = file.read()\n","      labels = labels.split('\\n')\n","      for line in labels:\n","        line = line.strip('\\n')\n","        if len(line.split(',')) == 4:\n","          file_reqd, temp_x, temp_y, temp_z = line.split(',') \n","          if file_reqd+'.png' in f:\n","            xs.append(float(temp_x))\n","            ys.append(float(temp_y))\n","            zs.append(float(temp_z))\n","  if(c == 15):\n","      break\n","\n","    \n","import pandas as pd\n","\n","df = pd.DataFrame({\"unique_id\":image_ids,'x':xs,'y':ys,'z':zs})\n","df.head()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>unique_id</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6679_000.png</td>\n","      <td>-0.133114</td>\n","      <td>-0.021778</td>\n","      <td>0.990861</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6679_001.png</td>\n","      <td>-0.127335</td>\n","      <td>-0.020104</td>\n","      <td>0.991656</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6679_002.png</td>\n","      <td>-0.133111</td>\n","      <td>-0.022769</td>\n","      <td>0.990839</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6679_003.png</td>\n","      <td>-0.127335</td>\n","      <td>-0.020104</td>\n","      <td>0.991656</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6679_005.png</td>\n","      <td>-0.126190</td>\n","      <td>-0.019146</td>\n","      <td>0.991821</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      unique_id         x         y         z\n","0  6679_000.png -0.133114 -0.021778  0.990861\n","1  6679_001.png -0.127335 -0.020104  0.991656\n","2  6679_002.png -0.133111 -0.022769  0.990839\n","3  6679_003.png -0.127335 -0.020104  0.991656\n","4  6679_005.png -0.126190 -0.019146  0.991821"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"TMV9uJt-48XS","colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"status":"ok","timestamp":1608902360965,"user_tz":-330,"elapsed":24409,"user":{"displayName":"Reshma Rameshbabu","photoUrl":"","userId":"00800467791840406492"}},"outputId":"beefd3f7-f240-4399-d243-01620d793afb"},"source":["image_ids = []\n","xs = []\n","ys = []\n","zs = []\n","c = 0\n","for dir, sub_dir, f in os.walk(\"/content/drive/My Drive/FYP/Dataset/entire/openEDS2020-GazePrediction/validation/sequences\"):\n","  if len(f) > 0:\n","    c += 1\n","    f = sorted(f)\n","    seq_id = dir.split(\"/\")[-1]\n","    temp_images_ids = [seq_id+'_'+x for x in f]\n","    image_ids.extend(temp_images_ids)\n","    with open(\"/content/drive/My Drive/FYP/Dataset/entire/openEDS2020-GazePrediction/validation/labels/\"+seq_id+\".txt\", mode = \"r\") as file:\n","      labels = file.read()\n","      labels = labels.split('\\n')\n","      for line in labels:\n","        line = line.strip('\\n')\n","        if len(line.split(',')) == 4:\n","          file_reqd, temp_x, temp_y, temp_z = line.split(',') \n","          if file_reqd+'.png' in f:\n","            xs.append(float(temp_x))\n","            ys.append(float(temp_y))\n","            zs.append(float(temp_z))\n","  if(c == 15):\n","      break\n","\n","    \n","import pandas as pd\n","\n","df1 = pd.DataFrame({\"unique_id\":image_ids,'x':xs,'y':ys,'z':zs})\n","df1.head()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>unique_id</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7960_000.png</td>\n","      <td>0.204384</td>\n","      <td>0.111141</td>\n","      <td>0.972561</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7960_001.png</td>\n","      <td>0.203746</td>\n","      <td>0.110971</td>\n","      <td>0.972714</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7960_002.png</td>\n","      <td>0.202203</td>\n","      <td>0.110214</td>\n","      <td>0.973122</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7960_003.png</td>\n","      <td>0.201722</td>\n","      <td>0.110209</td>\n","      <td>0.973223</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7960_004.png</td>\n","      <td>0.201057</td>\n","      <td>0.110906</td>\n","      <td>0.973281</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      unique_id         x         y         z\n","0  7960_000.png  0.204384  0.111141  0.972561\n","1  7960_001.png  0.203746  0.110971  0.972714\n","2  7960_002.png  0.202203  0.110214  0.973122\n","3  7960_003.png  0.201722  0.110209  0.973223\n","4  7960_004.png  0.201057  0.110906  0.973281"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"IDCqSTHjRPZb","colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"status":"ok","timestamp":1608902427211,"user_tz":-330,"elapsed":64621,"user":{"displayName":"Reshma Rameshbabu","photoUrl":"","userId":"00800467791840406492"}},"outputId":"a069fbc3-477c-4544-c50a-4ca54d1f3371"},"source":["image_ids = []\n","\n","c = 0\n","for dir, sub_dir, f in os.walk(\"/content/drive/My Drive/FYP/Dataset/entire/openEDS2020-GazePrediction/test/sequences\"):\n","  if len(f) > 0:\n","    c += 1\n","    f = sorted(f)\n","    seq_id = dir.split(\"/\")[-1]\n","    temp_images_ids = [seq_id+'_'+x for x in f]\n","    image_ids.extend(temp_images_ids)\n","\n","  if (c == 50):\n","    break\n","\n","import pandas as pd\n","\n","df2 = pd.DataFrame({\"unique_id\":image_ids})\n","df2.head()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>unique_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5401_000.png</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5401_001.png</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5401_002.png</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5401_003.png</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5401_004.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      unique_id\n","0  5401_000.png\n","1  5401_001.png\n","2  5401_002.png\n","3  5401_003.png\n","4  5401_004.png"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"K5TJNsgk1PJa","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"ok","timestamp":1608896365194,"user_tz":-330,"elapsed":982,"user":{"displayName":"Reshma Rameshbabu","photoUrl":"","userId":"00800467791840406492"}},"outputId":"a6a26ef5-499b-49d2-99b4-a728a28cfeef"},"source":["df2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>unique_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5401_000.png</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5401_001.png</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5401_002.png</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5401_003.png</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5401_004.png</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1361</th>\n","      <td>5449_044.png</td>\n","    </tr>\n","    <tr>\n","      <th>1362</th>\n","      <td>5449_045.png</td>\n","    </tr>\n","    <tr>\n","      <th>1363</th>\n","      <td>5449_046.png</td>\n","    </tr>\n","    <tr>\n","      <th>1364</th>\n","      <td>5449_047.png</td>\n","    </tr>\n","    <tr>\n","      <th>1365</th>\n","      <td>5449_048.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1366 rows Ã— 1 columns</p>\n","</div>"],"text/plain":["         unique_id\n","0     5401_000.png\n","1     5401_001.png\n","2     5401_002.png\n","3     5401_003.png\n","4     5401_004.png\n","...            ...\n","1361  5449_044.png\n","1362  5449_045.png\n","1363  5449_046.png\n","1364  5449_047.png\n","1365  5449_048.png\n","\n","[1366 rows x 1 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"pAyUVxParU0M"},"source":["class EyeGazeData(Dataset):\n","    def __init__(self,data_df,data_dir = './',transform=None,train=True):\n","        super().__init__()\n","        self.data_df = data_df\n","        self.data_dir = data_dir\n","        self.transform = transform\n","        self.train = train\n","    \n","    def __len__(self):\n","        return self.data_df.shape[0]\n","    \n","    def __getitem__(self,item):\n","        if self.train:\n","          uid,x,y,z = self.data_df.iloc[item]\n","        else:\n","          uid = self.data_df.iloc[item]['unique_id']\n","        #uid,x,y,z = self.data_df.iloc[item]\n","        seq_id,filename = uid.split('_')\n","        img_path = os.path.join(self.data_dir+'/'+seq_id,filename)\n","        img = cv2.imread(img_path,1)\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        if self.train:\n","          return {\n","              'img' : img,\n","              'label_x' : torch.tensor(x),\n","              'label_y' : torch.tensor(y),\n","              'label_z' : torch.tensor(z),\n","                }\n","        else: \n","          return {'img':img}\n","        \n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kz4W1D150djK"},"source":["data_transform = transforms.Compose([transforms.ToPILImage(),\n","                                     transforms.Resize(299), \n","                                     transforms.CenterCrop(299), \n","                                     transforms.ToTensor(), \n","                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","\n","train_dataset = EyeGazeData(df, '/content/drive/My Drive/FYP/Dataset/entire/openEDS2020-GazePrediction/train/sequences',data_transform)\n","train_loader = DataLoader(train_dataset, batch_size=32, num_workers=0, shuffle=True)\n","\n","val_dataset = EyeGazeData(df1, '/content/drive/My Drive/FYP/Dataset/entire/openEDS2020-GazePrediction/validation/sequences',data_transform)\n","val_loader = DataLoader(val_dataset, batch_size=32, num_workers=0, shuffle=True)\n","\n","test_dataset = EyeGazeData(df2, '/content/drive/My Drive/FYP/Dataset/entire/openEDS2020-GazePrediction/test/sequences',data_transform,train=False)\n","test_loader = DataLoader(val_dataset, batch_size=32, num_workers=0, shuffle=True)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_A3SKGu31bol","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608896409681,"user_tz":-330,"elapsed":1286,"user":{"displayName":"Reshma Rameshbabu","photoUrl":"","userId":"00800467791840406492"}},"outputId":"b57330d7-a584-4485-9f64-d5ec6f9051c4"},"source":["test_dataset.__getitem__(1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'img': tensor([[[-1.6213, -1.6213, -1.6213,  ..., -1.9295, -1.9467, -1.9467],\n","          [-0.5424, -0.5424, -0.5424,  ..., -1.2788, -1.2788, -1.3302],\n","          [-0.5938, -0.5938, -0.6109,  ..., -1.0390, -1.0390, -1.0733],\n","          ...,\n","          [-0.8164, -0.8164, -0.7993,  ..., -1.7583, -1.7583, -1.7754],\n","          [-0.8335, -0.8164, -0.7650,  ..., -1.7583, -1.7754, -1.7754],\n","          [-0.8507, -0.8164, -0.7822,  ..., -1.7583, -1.7754, -1.7583]],\n"," \n","         [[-1.5280, -1.5280, -1.5280,  ..., -1.8431, -1.8606, -1.8606],\n","          [-0.4251, -0.4251, -0.4251,  ..., -1.1779, -1.1779, -1.2304],\n","          [-0.4776, -0.4776, -0.4951,  ..., -0.9328, -0.9328, -0.9678],\n","          ...,\n","          [-0.7052, -0.7052, -0.6877,  ..., -1.6681, -1.6681, -1.6856],\n","          [-0.7227, -0.7052, -0.6527,  ..., -1.6681, -1.6856, -1.6856],\n","          [-0.7402, -0.7052, -0.6702,  ..., -1.6681, -1.6856, -1.6681]],\n"," \n","         [[-1.2990, -1.2990, -1.2990,  ..., -1.6127, -1.6302, -1.6302],\n","          [-0.2010, -0.2010, -0.2010,  ..., -0.9504, -0.9504, -1.0027],\n","          [-0.2532, -0.2532, -0.2707,  ..., -0.7064, -0.7064, -0.7413],\n","          ...,\n","          [-0.4798, -0.4798, -0.4624,  ..., -1.4384, -1.4384, -1.4559],\n","          [-0.4973, -0.4798, -0.4275,  ..., -1.4384, -1.4559, -1.4559],\n","          [-0.5147, -0.4798, -0.4450,  ..., -1.4384, -1.4559, -1.4384]]])}"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"dSm9fvNbcJk3"},"source":["Regression Training"]},{"cell_type":"code","metadata":{"id":"UiZKA4IaL8YG"},"source":["import numpy as np\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from google.cloud import storage\n","\n","\n","def get_off_accuracy_regression(model, data_loader, GPU= 0):\n","    p=0\n","    freq_pos = np.zeros(81)\n","    freq_neg = np.zeros(80)\n","    for img, label in data_loader:\n","        out = model(img)\n","        #out = out.int()\n","        label = label.cuda(GPU)\n","\n","        for i in range(0,len(label)):\n","            diff = label[i]+1 - out[i].int()\n","            if diff>=0:\n","                freq_pos[diff] +=1\n","            else:\n","                freq_neg[diff] +=1\n","\n","    diffs = []\n","    for n in range(-80, 81):\n","        diffs.append(n)\n","    \n","    freq_total = np.concatenate((freq_neg, freq_pos))\n","    freq_total = freq_total/freq_total.sum()\n","    plt.bar(diffs[50:110], freq_total[50:110])\n","    plt.title(\"Distribution of Actual-Prediction\")\n","    plt.xlabel(\"difference value\")\n","    plt.ylabel(\"prob\")\n","    print(\"+/- 1 year accuracy: {:.2f}%\".format(freq_total[79:81].sum()*100))\n","    print(\"+/- 5 years accuracy: {:.2f}%\".format(freq_total[75:86].sum()*100))\n","    print(\"+/- 10 years accuracy: {:.2f}%\".format(freq_total[70:91].sum()*100))\n","    \n","    return\n","    \n","  \n","def evaluate_regression(data_eval, net, criterion, batch_size =32, GPU = 0):\n","    total_epoch = 0\n","    total_loss = 0\n","    for inputs, labels in data_eval:\n","        outputs = net(inputs.cuda(GPU))\n","        loss = criterion(outputs.cuda(GPU), labels.float().cuda(GPU))\n","        total_loss += loss.item()\n","        total_epoch += len(labels)\n","    return float(total_loss)/(total_epoch)\n","  \n","    \n","def train_regression(train_loader, val_loader, model, pretrained = False, checkpoint = None, model_name = 'VGG', batch_size=32, learning_rate=5e-05, n_epochs=30, GPU= 0):\n","    \n","    \n","    # Fixed PyTorch random seed for reproducible result\n","    from torch.autograd import Variable\n","    torch.manual_seed(1000)\n","    \n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    criterion = nn.CrossEntropyLoss().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n","    \n","    pretrained_epoch = 0\n","    train_losses, valid_losses, train_acc, val_acc = [], [], [], []\n","    if pretrained == True:\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        pretrained_epoch = checkpoint['epoch']\n","        train_losses = checkpoint['train_loss']\n","        valid_losses = checkpoint['valid_loss']\n","        model.train()\n","        print(\"resuming training after epoch: \", pretrained_epoch)\n","    \n","    # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n","    # Train the network\n","    # Loop over the data iterator and sample a new batch of training data\n","    # Get the output from the network, and optimize our loss function.\n","    \n","    valid_loss_min = np.Inf\n","    start_time = time.time()\n","    for epoch in range(n_epochs):\n","        train_loss = 0.0\n","        valid_loss = 0.0\n","        \n","        model.train()\n","        for images in train_loader:\n","            data = images['img'].squeeze(0).to(device)\n","            # data = data.squeeze(0)\n","            targetx = images['label_x'].to(device)\n","            targety = images['label_y'].to(device)\n","            targetz = images['label_z'].to(device)\n","            #clear the gradients of all optimized variables\n","            optimizer.zero_grad()\n","            #forward pass the model\n","            output = model(data)\n","            #backward pass the model\n","            #loss = criterion(output,targetx.long())\n","            lossx = criterion(output,targetx.long())\n","            lossy = criterion(output,targety.long())\n","            lossz = criterion(output,targetz.long())\n","            loss = lossx + lossy + lossz\n","            loss.backward()\n","            #Perform a single optimization step\n","            optimizer.step()\n","            train_loss += loss.item()*data.size(0)\n","\n","        model.eval()\n","        for images in val_loader:\n","            data = images['img'].squeeze(0).to(device)\n","            targetx = images['label_x'].to(device)\n","            targety = images['label_y'].to(device)\n","            targetz = images['label_z'].to(device)\n","            target = targetx + targety + targetz\n","            #forward pass now\n","            output = model(data)\n","            #calculate the branch loss\n","            loss = criterion(output, target.long())\n","            #update average validation loss\n","            valid_loss += loss.item()*data.size(0)\n","        \n","        train_loss /= len(train_loader.sampler)\n","        valid_loss /= len(val_loader.sampler)\n","        \n","        train_losses.append(train_loss)\n","        valid_losses.append(valid_loss)\n","        \n","        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","            epoch, train_loss, valid_loss))\n","        \n","        if valid_loss <= valid_loss_min:\n","            print(\"Validation Loss decreased {:0.6f} -> {:0.6f}\".format(valid_loss_min,valid_loss))\n","            valid_loss_min = valid_loss\n","            torch.save(model.state_dict(), 'best_model_so_far.pth')\n","    \n","    \n","    # plotting\n","    plt.title(\"Loss curves w/ lr={}, batch size = {}\".format(learning_rate, batch_size))\n","    plt.axis([0, n_epochs, 0, max(train_losses[0], valid_losses[0])])\n","    plt.plot(train_losses, label=\"Train loss\")\n","    plt.plot(valid_losses, label=\"Validation loss\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.show()\n","\n","    print(\"Final Training Loss: {}\".format(train_losses[-1]))\n","    print(\"Final Validation Loss: {}\".format(valid_losses[-1]))\n","\n","    print('Finished Training')\n","    end_time = time.time()\n","    elapsed_time = end_time - start_time\n","    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n","    \n","    return\n","\n","def regression_demo(data, model):\n","    k = 0\n","    for img, label in data:\n","        #img = img / 2 + 0.5\n","        #plt.subplot(3, 5, k+1)\n","        #plt.axis('off')\n","        pred = model(img)\n","        for count, i in enumerate(img, 0):\n","            print(count)\n","            i = np.transpose(i, [1,2,0])\n","            plt.imshow(i)\n","            plt.show()\n","            print(\"Actual: \", label[count], \" Prediction: \", pred[count])\n","            k += 1\n","        #print(label, vgg_regression(img))\n","            if k > 10:\n","                break\n","\n","        break\n","    \n","    return"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wbv9rHmDcOp5"},"source":["Inception"]},{"cell_type":"code","metadata":{"id":"qcN_9ujyO8l_","colab":{"base_uri":"https://localhost:8080/","height":102,"referenced_widgets":["ad4adcab6f56456c913e9a744c4d22cd","18bd5cd59b4640bb8000358765aaa96c","f7fe7633f5174686b00d66b1f4ad16b7","81cb44a81a4d463a8d6fc0608b088192","708f0de04cb54d9080d4f3898fcfe7d7","54c63c8d99964463990f3f7add5fe9aa","970c2f54ad03494b9b572fe52f92954c","90ad6fbbfcba4f7999ff0abd41cc7629"]},"executionInfo":{"status":"ok","timestamp":1608902473449,"user_tz":-330,"elapsed":1646,"user":{"displayName":"Reshma Rameshbabu","photoUrl":"","userId":"00800467791840406492"}},"outputId":"95015b94-60d5-456b-b80b-be7ecdddfc86"},"source":["from __future__ import print_function\n","from __future__ import division\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","\n","inception = models.inception_v3(pretrained=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad4adcab6f56456c913e9a744c4d22cd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=108857766.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qnakiPVwPFLl"},"source":["inception.cuda()\n","inception.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JURhNkUtPOGY"},"source":["class inception_regression(nn.Module):\n","    def __init__(self):\n","        super(inception_regression, self).__init__()\n","        self.name = \"inception_regression\"\n","        self.fc1 = nn.Linear(1000, 1) #x\n","        #self.fc2 = nn.Linear(512, 512)\n","        self.fc2 = nn.Linear(1000, 1) #y\n","        self.fc3 = nn.Linear(1000, 1) #z\n","        self.dropout = nn.Dropout(0.2)\n","    \n","    def forward(self, x):\n","        x = x.cuda()\n","        x = inception(x)\n","        x = x.view(x.shape[0],-1)\n","        label1 = self.fc1(x)\n","        label2= torch.sigmoid(self.fc2(x))  \n","        label3= self.fc3(x)\n","        return {'label_x': label1, 'label_y': label2, 'label_z': label3}\n","\n","        '''x.view(x.shape[0],-1)\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = F.relu(self.fc2(x))\n","        x = self.dropout(x)\n","        x = self.fc3(x)\n","        x = x.squeeze(1)\n","\n","        y = y.cuda()\n","        y = inception(y)\n","        y = y.view(y.shape[0],-1)\n","        y = F.relu(self.fc1(y))\n","        y = self.dropout(y)\n","        y = F.relu(self.fc2(y))\n","        y = self.dropout(y)\n","        y = self.fc3(y)\n","        y = y.squeeze(1)\n","\n","        z = z.cuda()\n","        z = inception(z)\n","        z = z.view(z.shape[0],-1)\n","        z = F.relu(self.fc1(z))\n","        z = self.dropout(z)\n","        z = F.relu(self.fc2(z))\n","        z = self.dropout(z)\n","        z = self.fc3(z)\n","        z = z.squeeze(1)'''\n","\n","        #return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a_gLFMYxPVIm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608902803559,"user_tz":-330,"elapsed":1157,"user":{"displayName":"Reshma Rameshbabu","photoUrl":"","userId":"00800467791840406492"}},"outputId":"c41e9e9c-314f-4d24-8957-afe88bc04c71"},"source":["inc_regression = inception_regression()\n","inc_regression.cuda()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["inception_regression(\n","  (fc1): Linear(in_features=1000, out_features=1, bias=True)\n","  (fc2): Linear(in_features=1000, out_features=1, bias=True)\n","  (fc3): Linear(in_features=1000, out_features=1, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"YxIcg5YRPaU-","colab":{"base_uri":"https://localhost:8080/","height":313},"executionInfo":{"status":"error","timestamp":1608902939825,"user_tz":-330,"elapsed":1288,"user":{"displayName":"Reshma Rameshbabu","photoUrl":"","userId":"00800467791840406492"}},"outputId":"6f477704-a072-41e0-c899-52b2f3b9dcf1"},"source":["train_regression(train_loader, val_loader, inc_regression, model_name = 'INCEPTION', batch_size = 32, n_epochs = 10)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-49f33b656e72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_regression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'INCEPTION'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-24-a8af4b435fba>\u001b[0m in \u001b[0;36mtrain_regression\u001b[0;34m(train_loader, val_loader, model, pretrained, checkpoint, model_name, batch_size, learning_rate, n_epochs, GPU)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0;31m# data = data.squeeze(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mtargetx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 34.00 MiB (GPU 0; 14.73 GiB total capacity; 13.52 GiB already allocated; 19.88 MiB free; 13.78 GiB reserved in total by PyTorch)"]}]}]}